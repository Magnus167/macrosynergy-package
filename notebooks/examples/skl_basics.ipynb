{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General technical points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main API (Application Programming Interface) implemented by scikit-learn is that of the **estimator**. An estimator is any object that learns from data; it may be a classification, regression or clustering algorithm or a transformer that extracts or filters useful features from raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn all machine learning models are implemented as python classes. This means in particular that\n",
    "* they implement learning and predicting,\n",
    "* they store information learned form the data,\n",
    "* their .fit() methods govern fitting or training a model, and\n",
    "* their .predict() methods are used to predict unlabelled data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the scikit API requires:\n",
    "* all data to be in standard numpy or pandas format with features as columns and samples as rows,\n",
    "* no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning means methods that allow computers to learn from data. If the data have labels, this is called supervised learning, i.e. the 'right' outcome is known.\n",
    "Supervised learning typically has feature variables (predictor variables) and a target variable.\n",
    "The two basic versions are [1] classification and [2] regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **feature space** for supervised learning comes in form of a samples matrix (or design matrix) X. Typically samples are in rows and features are in column. The **target space** usually comes in form of a vector y.\n",
    "\n",
    "Thus, an estimator for classification is a Python object that implements the methods **fit(X_train, y_train)** and **predict(X_test)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification trains a model with labelled features for the purpose of categorization unlabelled features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris data set offers a 3-dimensional classification challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features dimension: (150, 4).\n",
      "Labels dimensions (150,).\n",
      "Labels:[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)  # extract features and labels\n",
    "print(f'Features dimension: {iris_X.shape}.\\nLabels dimensions {iris_y.shape}.\\nLabels:{np.unique(iris_y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn supports the creation of stratified training and testing samples of unordered data through random permutation.\n",
    "\n",
    "N.B.: **Stratified sampling** is a method of sampling from a population by dividing members of the population into homogeneous subgroups. The use stratified sampling ensures that relative class frequencies are approximately preserved in train/validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection as skmos\n",
    "X_train, X_test, y_train, y_test = skmos.train_test_split(iris_X, iris_y, test_size=0.3, random_state=21, stratify=iris_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-neighbours classifier must be first instantiated and then fitted to the traing data, using features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # instantiate estimator\n",
    "knn.fit(X_train, y_train)  # fit the estimator\n",
    "y_pred = knn.predict(X_test)  # predict test targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier fitting returns:\n",
    "* the classifier itself and\n",
    "* a modification to fit it to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to measure accuracy based on the test sample is the **.score()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_X, boston_y = datasets.load_boston(return_X_y=True)\n",
    "\n",
    "from sklearn import model_selection as skmos\n",
    "X_train, X_test, y_train, y_test = skmos.train_test_split(boston_X, boston_y, test_size=0.3, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()  # instantiate regression\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7115848967731223"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test, y_test)  # get R2 without need to .predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation: k-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of testing is to estimate a models quality of predicting data out of sample. For the purpose of testing a single split of the data has greater risk of of not being representative for a model's ability to generalize. Hence, where possible, multiple splits are preferred. An unordered dataset is typically split into folds. <u>Out of k folds each one is used as test set in turn</u>. There are as many train-test splits and scores as there are folds.\n",
    "\n",
    "This maximizes the amount of data that is used to train the model, as during the course of training, the model is not only trained, but also tested on all of the available data. However, <u>the number of folds also determines the computational cost</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63919994  0.71386698  0.58702344  0.07923081 -0.25294154]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "boston_X, boston_y = datasets.load_boston(return_X_y=True)\n",
    "reg = LinearRegression()\n",
    "cv_results = cross_val_score(reg, boston_X, boston_y, cv=5)  # gives array of R2s\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tryouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/tutorial/index.html#tutorial-menu\n",
    "\n",
    "now:\n",
    "https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
