{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)  # extract features and labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label of the new point from these. This is the simplest possible classifier.\n",
    "\n",
    "Put simply the KNN classifier takes the k closest neighbours of an unlabelled datapoint, measures closeness according to all relevant dimensions and classifies unlabelled data point by majority vote. Thereby the classifier creates a set of **'decision boundaries'**.\n",
    "\n",
    "The number k determines how many samples are considered relevant neighbors. A <u>low k is selective and fits the labels close to the training data</u>. This implies a complex model that is prone to **overfitting**. A high k is inclusive. It implies a smooth decision boundary and a simpler model, but - if taken too far - runs the risk of ignoring training data patterns, i.e **underfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=0.3, random_state=21, stratify=iris_y)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # instantiate estimator\n",
    "knn.fit(X_train, y_train)  # fit the estimator\n",
    "y_pred = knn.predict(X_test)  # predict test targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.: **Stratified sampling** is a method of sampling from a population by dividing members of the population into homogeneous subgroups. The use stratified sampling ensures that relative class frequencies are approximately preserved in train/validation folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True) \n",
    "y = ['pos' if (i == 2) else 'neg' for i in y]  # convert classes to binary base\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=iris_y)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # instantiate estimator\n",
    "knn.fit(X_train, y_train)  # fit the estimator\n",
    "y_pred = knn.predict(X_test)  # predict test targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confusion matrix** informs on predicted and actual classifications. In the binary case, the stylized labels of often positives (class of interest) and negatives. The confusion matrix of a prediction model divides all cases into four categories: \n",
    "* A *true positive* is a case that is classified and predicted as positive.\n",
    "* A *false positive* is a case that is classified as positive but predicted as negative.\n",
    "* A *true negative* is a case that is classified and predicted as negative.\n",
    "* A *false negative*  is a case that is classified as negative but predicted as positive.\n",
    "\n",
    "Binary classification evaluation metrics are calculated based on the frequencies of these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64444444 0.02222222]\n",
      " [0.         0.33333333]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18a4520f1f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cfm = metrics.confusion_matrix(y_test, y_pred, normalize='all', labels = ['pos', 'neg'])  # simple normalized confusion matrix\n",
    "print(cfm)\n",
    "metrics.plot_confusion_matrix(knn, X_test, y_test, normalize='all', labels = ['pos', 'neg'])  # applied directly to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key confusion-based evaluation metrics include the following:\n",
    "\n",
    "* **Accuracy**, the fraction of correctly classified samples. In the binary case it is the ratio of true positives and true negatives to all labelled cases, where means correctly labelled by the model. However, accuracy may not br meaningful for data with *class imbalance*, i.e. some classes being dominant. For example, for a binary series with dominant positive values, accuracy mainly depends on the correct labelling of the positive cases. The correct labelling of negative cases would not matter much.\n",
    "\n",
    "* **Precision** is the ratio of true positives, i.e. correctly labelled positives, to all cases (true and false or correcty and incorrectly labelled) that are classified as positives. This is a useful metric if the prediction of positives should be as 'precise' as possible, i.e  capture positives without capturing too many negatives. It is a metric of avoidance of mistakes.\n",
    "\n",
    "* **Recall** is the ratio of true to positives to all cases that are classified as positives. This is also call hit rate and makes sense if the main objective is to catch as many positives as possible. There is no penalty for incorrectly labelled positives. It is metric of avoidance of missing out. In binary classification, recall of the positive class is also known as **sensitivity** and the recall of the negative class as **specificity**.\n",
    "\n",
    "There is evidently a trade-off between precision and recall. The greater the emphasis on avoiding false positives, the greater the emphasis on precision. The more one focuses on avoiding missing out on positive, the greater the emphasis on recall.\n",
    "In a classifier the trade-off is often managed through the threshold level that divides the classification. Typically, <u>a low threshold gives low precision but high recall</u>. A high threshold gives high precision but low recall.\n",
    "The **Receiver Operating Characteristic (ROC) curve** shows how the recall versus precision relationship changes as we vary the threshold for identifying a positive in our model.\n",
    "* For a good blend of precision and recall we can combine the two metrics to an the **F1 score**. The F1 score is the <u>harmonic mean of precision and recall values</u>, taking both metrics into account. It is precision times recall divided by the average of precision and recall. The harmonic mean punishes extreme values. SKL offers various F1 scores for binary, averaged, and multilabel samples.\n",
    "* The **average precision score** summarizes a precision-recall curve as the <u>weighted mean of precisions achieved at each threshold</u>, with the increase in recall from the previous threshold used as the weight. This only works with a binary class.\n",
    "\n",
    "Note that <u>precision, recall and F1 score are specific to the class</u>. This means that they are generally different for positives and negatives. Hence, it matters what we consider to be the 'class of interest'. Since, sklearn does not know what is of interest it calculates the statistics for both classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       1.00      0.97      0.98        30\n",
      "         neg       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred, labels = ['pos', 'neg']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In its default classification report sklearn also informs about the following:\n",
    "\n",
    "* **Support** gives the number of samples of the true response that lie in the respective class.\n",
    "* **Macro average** gives the average unweighted mean of precision/recall/F1 across labels.\n",
    "* **Weighted average** gives the support-weighted mean of  precision/recall/F1 across labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tryouts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
